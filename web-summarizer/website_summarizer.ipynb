{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f9f303-335d-4a4f-93c3-73715327abb8",
   "metadata": {},
   "source": [
    "# Day1 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c17c5-ed02-42c4-8947-c3cc0515f1d1",
   "metadata": {},
   "source": [
    "# 1. Website Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca2af7-0f62-4728-af86-5dca338b5e57",
   "metadata": {},
   "source": [
    "Here the user will enter the website he wants to summarize, the llms will provide a clear concise use of the website. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c505d-3873-4bb6-9b94-50820c7b6d64",
   "metadata": {},
   "source": [
    "### Modules to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262412b-635e-4937-86a9-bdde0ae4b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# System & Environment\n",
    "# =======================\n",
    "\n",
    "import os\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# =======================\n",
    "# Web scraping\n",
    "# =======================\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By  # type: ignore\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# ========================\n",
    "# AI-related\n",
    "# ========================\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb1970-d701-416a-ba75-0e11173b64dc",
   "metadata": {},
   "source": [
    "### Check for api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df42871-4bdd-46d8-8b96-35459c66f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check for api key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found\")\n",
    "\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API KEY was found but doesn't start sk-proj-\")\n",
    "\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API KEY was found, but it looks like it might have space or tab characters at the start or end\")\n",
    "\n",
    "else:\n",
    "    print(\"API KEY found and looks good\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdc755-6e44-4813-b515-d5f7fab3ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OLLAMA = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adee3126",
   "metadata": {},
   "source": [
    "WEB SUMMARIZER INFRASTRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21554af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class WebSummarizer:\n",
    "    def __init__(self, url, model_name=MODEL_OLLAMA):\n",
    "        self.url = url\n",
    "        self.model_name = model_name\n",
    "        self.title = \"\"\n",
    "        self.text = \"\"\n",
    "        self.scrape()\n",
    "\n",
    "    def scrape(self):\n",
    "        try:\n",
    "            # Chrome options\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "            chrome_options.add_argument(\"--no-sandbox\")\n",
    "            chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "            chrome_options.add_argument(\"--disable-gpu\")\n",
    "            chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "            chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "            # Try to find Chrome\n",
    "            chrome_paths = [\n",
    "                r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\",\n",
    "                r\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\",\n",
    "                r\"C:\\Users\\{}\\AppData\\Local\\Google\\Chrome\\Application\\chrome.exe\".format(os.getenv('USERNAME')),\n",
    "            ]\n",
    "\n",
    "            chrome_binary = None\n",
    "            for path in chrome_paths:\n",
    "                if os.path.exists(path):\n",
    "                    chrome_binary = path\n",
    "                    break\n",
    "\n",
    "            if chrome_binary:\n",
    "                chrome_options.binary_location = chrome_binary\n",
    "\n",
    "            # Create driver with webdriver-manager (with fallback)\n",
    "            try:\n",
    "                service = Service(ChromeDriverManager().install())\n",
    "                driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not use webdriver-manager: {e}\")\n",
    "                # Fallback to system Chrome driver\n",
    "                driver = webdriver.Chrome(options=chrome_options)\n",
    "            \n",
    "            driver.set_page_load_timeout(30)\n",
    "\n",
    "            print(f\"Loading: {self.url}\")\n",
    "            driver.get(self.url)\n",
    "\n",
    "            # Wait for page to load \n",
    "            time.sleep(5)\n",
    "\n",
    "            # Try to wait for main content\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"main\"))\n",
    "                )\n",
    "            except Exception:\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                    )\n",
    "                except Exception:\n",
    "                    pass  # Continue anyway\n",
    "\n",
    "            # Get title and page source\n",
    "            self.title = driver.title\n",
    "            page_source = driver.page_source\n",
    "            driver.quit()\n",
    "\n",
    "            print(f\"Page loaded: {self.title}\")\n",
    "\n",
    "            # Parse with BeautifulSoup\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Remove unwanted elements\n",
    "            for element in soup([\"script\", \"style\", \"img\", \"input\", \"button\", \"nav\", \"footer\", \"header\"]):\n",
    "                element.decompose()\n",
    "\n",
    "            # Get main content\n",
    "            main = soup.find('main') or soup.find('article') or soup.select_one('.content') or soup.find('body')\n",
    "            if main:\n",
    "                self.text = main.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "            # Clean up text\n",
    "            lines = [line.strip() for line in self.text.split('\\n') if line.strip() and len(line.strip()) > 2]\n",
    "            self.text = '\\n'.join(lines[:200])  # Limit to first 200 lines\n",
    "\n",
    "            print(f\"Extracted {len(self.text)} characters\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            self.title = \"Error occurred\"\n",
    "            self.text = \"Could not scrape website content\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e5c70",
   "metadata": {},
   "source": [
    "Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8004463",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296de1b4",
   "metadata": {},
   "source": [
    "Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1abb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_ollama(url):\n",
    "    \"\"\"Scrape website and summarize with Ollama\"\"\"\n",
    "    site = WebSummarizer(url)\n",
    "\n",
    "    if \"Error occurred\" in site.title or len(site.text) < 50:\n",
    "        print(f\"Failed to scrape meaningful content from {url}\")\n",
    "        return\n",
    "\n",
    "    print(\"Creating summary...\")\n",
    "\n",
    "    try:\n",
    "        # Create summary using Ollama\n",
    "        response = ollama.chat(\n",
    "            model=MODEL_OLLAMA,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt_for(site)}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Handle response format (ollama returns dict with 'message' key)\n",
    "        if isinstance(response, dict):\n",
    "            web_summary = response.get('message', {}).get('content', '')\n",
    "        elif hasattr(response, 'message'):\n",
    "            web_summary = getattr(response.message, 'content', '')\n",
    "        else:\n",
    "            web_summary = str(response)\n",
    "        \n",
    "        if web_summary:\n",
    "            display(Markdown(web_summary))\n",
    "        else:\n",
    "            print(f\"Failed to generate summary. Response: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "summarize_ollama('https://openai.com')\n",
    "# summarize_ollama('https://stripe.com')\n",
    "# summarize_ollama('https://vercel.com')\n",
    "# summarize_ollama('https://www.idcam.cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a7605-d033-4d47-aabd-153a51b96a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
